{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e48ce926-d3fb-4fec-94c6-a3046dcbdda7",
   "metadata": {},
   "source": [
    "### Q1 Getting the embeddings model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "51ae1198-c237-488a-9272-57ad172f3a5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dmitry/venv/lib/python3.12/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:11: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n",
      "2024-07-13 16:23:05.874201: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-07-13 16:23:05.891785: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:479] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-07-13 16:23:05.915834: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:10575] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-07-13 16:23:05.915884: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1442] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-07-13 16:23:05.932660: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-13 16:23:08.702958: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/home/dmitry/venv/lib/python3.12/site-packages/torch/cuda/__init__.py:619: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6167218f430431e8d46f43e379a8f5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1c6db9916284efa93110b4df936e5cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3709fad3d9cf4207afba4cce07d9048f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/9.52k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "382e53c0ccd14da1bbfbcdd1bfff355e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a5e31a6007e41b4807fe4c88e7d26e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/523 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38474fd9d9b84956b8a3dc7b09239e3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/265M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b553af68ff6c43d3aa2ffb47a7c7b0f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/333 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27df4cb91fa6428ab2344547085b3045",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bc6b3eb69864a6a80ddf5e107056b01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf7f735db82f4b1fa6b6df1213bc8ac6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf724943a2db4744877ec5ae8a6793d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer 1:  0.0782226\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Get the model\n",
    "embedding_model = SentenceTransformer(\"multi-qa-distilbert-cos-v1\")\n",
    "\n",
    "# Define the question\n",
    "user_question = \"I just discovered the course. Can I still join it?\"\n",
    "\n",
    "# Create a vector\n",
    "q_vector = embedding_model.encode(user_question)\n",
    "\n",
    "print(\"Answer 1: \", q_vector[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "79297ace-a052-4e0f-93ce-de92a59f6723",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests \n",
    "\n",
    "base_url = 'https://github.com/DataTalksClub/llm-zoomcamp/blob/main'\n",
    "relative_url = '03-vector-search/eval/documents-with-ids.json'\n",
    "docs_url = f'{base_url}/{relative_url}?raw=1'\n",
    "docs_response = requests.get(docs_url)\n",
    "documents = docs_response.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "704905b0-ccfb-420f-b411-541d30fb138d",
   "metadata": {},
   "source": [
    "### Q2 Creating the embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fa5105d1-1208-4138-b8e5-454622f7d3d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer 2: (948, 768)\n"
     ]
    }
   ],
   "source": [
    "# Create a list\n",
    "embeddings = []\n",
    "\n",
    "# Iterate over each document\n",
    "for doc in documents:\n",
    "    qa_text = f'{'question'} {'text'}'\n",
    "    \n",
    "    # Compute the embeddings\n",
    "    qa_text_vector = embedding_model.encode(qa_text)\n",
    "    embeddings.append(qa_text_vector)\n",
    "\n",
    "# Put all embeddings into a single matrix\n",
    "import numpy as np\n",
    "X = np.array(embeddings)\n",
    "\n",
    "# Check the shape\n",
    "print(\"Answer 2:\", X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9f426ed-7470-4d6b-bfae-717a32126279",
   "metadata": {},
   "source": [
    "### Q3 Computing cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b1085c2f-121d-4da8-8c67-802489adc01e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.04935043 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043\n",
      " 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043\n",
      " 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043\n",
      " 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043\n",
      " 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043\n",
      " 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043\n",
      " 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043\n",
      " 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043\n",
      " 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043\n",
      " 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043\n",
      " 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043\n",
      " 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043\n",
      " 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043\n",
      " 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043\n",
      " 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043\n",
      " 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043\n",
      " 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043\n",
      " 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043\n",
      " 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043\n",
      " 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043\n",
      " 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043\n",
      " 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043\n",
      " 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043\n",
      " 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043\n",
      " 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043\n",
      " 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043\n",
      " 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043\n",
      " 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043\n",
      " 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043\n",
      " 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043\n",
      " 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043\n",
      " 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043\n",
      " 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043\n",
      " 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043\n",
      " 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043\n",
      " 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043\n",
      " 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043\n",
      " 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043\n",
      " 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043\n",
      " 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043\n",
      " 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043\n",
      " 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043\n",
      " 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043\n",
      " 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043\n",
      " 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043\n",
      " 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043\n",
      " 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043\n",
      " 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043\n",
      " 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043\n",
      " 0.04935043 0.04935043 0.04935044 0.04935044 0.04935042 0.04935043\n",
      " 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043\n",
      " 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043\n",
      " 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043\n",
      " 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043\n",
      " 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043\n",
      " 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043\n",
      " 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043\n",
      " 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043\n",
      " 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043\n",
      " 0.04935043 0.04935044 0.04935044 0.04935042 0.04935043 0.04935043\n",
      " 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043\n",
      " 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043\n",
      " 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043\n",
      " 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043\n",
      " 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043\n",
      " 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043\n",
      " 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043\n",
      " 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043\n",
      " 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043\n",
      " 0.04935044 0.04935044 0.04935042 0.04935043 0.04935043 0.04935043\n",
      " 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043\n",
      " 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043\n",
      " 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043\n",
      " 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043\n",
      " 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043\n",
      " 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043\n",
      " 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043\n",
      " 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043\n",
      " 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043 0.04935044\n",
      " 0.04935044 0.04935042 0.04935043 0.04935043 0.04935043 0.04935043\n",
      " 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043\n",
      " 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043\n",
      " 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043\n",
      " 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043\n",
      " 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043\n",
      " 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043\n",
      " 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043\n",
      " 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043\n",
      " 0.04935043 0.04935043 0.04935043 0.04935043 0.04935044 0.04935044\n",
      " 0.04935042 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043\n",
      " 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043\n",
      " 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043\n",
      " 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043\n",
      " 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043\n",
      " 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043\n",
      " 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043\n",
      " 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043\n",
      " 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043\n",
      " 0.04935043 0.04935043 0.04935043 0.04935044 0.04935044 0.04935042\n",
      " 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043\n",
      " 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043\n",
      " 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043\n",
      " 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043\n",
      " 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043\n",
      " 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043\n",
      " 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043\n",
      " 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043\n",
      " 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043\n",
      " 0.04935043 0.04935043 0.04935044 0.04935044 0.04935042 0.04935043\n",
      " 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043\n",
      " 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043\n",
      " 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043\n",
      " 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043\n",
      " 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043\n",
      " 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043\n",
      " 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043\n",
      " 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043\n",
      " 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043\n",
      " 0.04935043 0.04935044 0.04935044 0.04935042 0.04935043 0.04935043\n",
      " 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043\n",
      " 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043\n",
      " 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043\n",
      " 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043\n",
      " 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043\n",
      " 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043\n",
      " 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043\n",
      " 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043\n",
      " 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043\n",
      " 0.04935044 0.04935044 0.04935042 0.04935043 0.04935043 0.04935043\n",
      " 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043\n",
      " 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043\n",
      " 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043\n",
      " 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043\n",
      " 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043\n",
      " 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043\n",
      " 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043\n",
      " 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043\n",
      " 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043 0.04935044\n",
      " 0.04935044 0.04935042 0.04935043 0.04935043 0.04935043 0.04935043\n",
      " 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043\n",
      " 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043\n",
      " 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043\n",
      " 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043\n",
      " 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043\n",
      " 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043\n",
      " 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043\n",
      " 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043\n",
      " 0.04935043 0.04935043 0.04935043 0.04935043 0.04935044 0.04935044\n",
      " 0.04935042 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043\n",
      " 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043\n",
      " 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043\n",
      " 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043\n",
      " 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043\n",
      " 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043\n",
      " 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043\n",
      " 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043\n",
      " 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043 0.04935043\n",
      " 0.04935043 0.04935043 0.04935043 0.04935044 0.04935044 0.04935042]\n"
     ]
    }
   ],
   "source": [
    "scores = X.dot(q_vector)\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e82b8b13-78e8-4307-a280-f890d05fb16f",
   "metadata": {},
   "source": [
    "### Search function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "743eb12a-8816-4878-b502-f038821e8353",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': 'Problem description\\nPre-commit command was failing with isort repo.\\nSolution description\\nSet version to 5.12.0\\nAdded by Erick Calderin',\n",
       "  'section': 'Module 6: Best practices',\n",
       "  'question': 'Isort Pre-commit',\n",
       "  'course': 'mlops-zoomcamp',\n",
       "  'id': 'fb3c4150'},\n",
       " {'text': 'Problem description\\nIf you are having problems with the integration tests and kinesis double check that your aws regions match on the docker-compose and local config. Otherwise you will be creating a stream in the wrong region\\nSolution description\\nFor example set ~/.aws/config region = us-east-1 and the docker-compose.yaml - AWS_DEFAULT_REGION=us-east-1\\nAdded by Quinn Avila',\n",
       "  'section': 'Module 6: Best practices',\n",
       "  'question': 'AWS regions need to match docker-compose',\n",
       "  'course': 'mlops-zoomcamp',\n",
       "  'id': '66326a87'},\n",
       " {'text': \"Problem: About week_2 homework: The register_model.py  script, when I copy it into a jupyter notebook fails and spits out the following error. AttributeError: 'tuple' object has no attribute 'tb_frame'\\nSolution: remove click decorators\",\n",
       "  'section': 'Module 2: Experiment tracking',\n",
       "  'question': \"AttributeError: 'tuple' object has no attribute 'tb_frame'\",\n",
       "  'course': 'mlops-zoomcamp',\n",
       "  'id': 'e223524c'},\n",
       " {'text': 'Problem: when running the preprocess_data.py file you get the following error:\\n\\nwandb: ERROR api_key not configured (no-tty). call wandb.login(key=[your_api_key])\\nSolution: Go to your WandB profile (top RHS) → user settings → scroll down to “Danger Zone” and copy your API key. \\n\\nThen before running preprocess_data.py, add and run the following cell in your notebook:\\n\\n%%bash\\n\\nWandb login <YOUR_API_KEY_HERE>.\\nAdded and Answered by James Gammerman (jgammerman@gmail.com)',\n",
       "  'section': 'Module 2: Experiment tracking',\n",
       "  'question': 'WandB API error',\n",
       "  'course': 'mlops-zoomcamp',\n",
       "  'id': '0f08bec7'},\n",
       " {'text': 'For many parts - yes. Some things like kinesis are not in AWS free tier, but you can do it locally with localstack.',\n",
       "  'section': 'Module 1: Introduction',\n",
       "  'question': 'Is the AWS free tier enough for doing this course?',\n",
       "  'course': 'mlops-zoomcamp',\n",
       "  'id': '9f69ca26'}]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class VectorSearchEngine():\n",
    "    def __init__(self, documents, embeddings):\n",
    "        self.documents = documents\n",
    "        self.embeddings = embeddings\n",
    "\n",
    "    def search(self, v_query, num_results=5):\n",
    "        scores = self.embeddings.dot(v_query)\n",
    "        idx = np.argsort(-scores)[:num_results]\n",
    "        return [self.documents[i] for i in idx]\n",
    "\n",
    "search_engine = VectorSearchEngine(documents=documents, embeddings=X)\n",
    "search_engine.search(q_vector, num_results=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14ad3aad-a664-4a27-b34e-9b86487c8a37",
   "metadata": {},
   "source": [
    "### Q4 Hit-rate for the search engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "afa54bd3-d2cb-4e1d-8ac5-4a5e56574387",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "base_url = 'https://github.com/DataTalksClub/llm-zoomcamp/blob/main'\n",
    "relative_url = '03-vector-search/eval/ground-truth-data.csv'\n",
    "ground_truth_url = f'{base_url}/{relative_url}?raw=1'\n",
    "\n",
    "df_ground_truth = pd.read_csv(ground_truth_url)\n",
    "df_ground_truth = df_ground_truth[df_ground_truth.course == 'machine-learning-zoomcamp']\n",
    "ground_truth = df_ground_truth.to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "964823e8-1e3b-400b-ae6a-0d85ad9ae7b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d8f2a18e436400f94f155c67861d591",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1830 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for *: 'float' and 'dict'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 26\u001b[0m\n\u001b[1;32m     22\u001b[0m             cnt \u001b[38;5;241m=\u001b[39m cnt \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cnt \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(relevance_total)\n\u001b[0;32m---> 26\u001b[0m \u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mground_truth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msearch_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[22], line 8\u001b[0m, in \u001b[0;36mevaluate\u001b[0;34m(ground_truth, search_function)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m q \u001b[38;5;129;01min\u001b[39;00m tqdm(ground_truth):\n\u001b[1;32m      7\u001b[0m     doc_id \u001b[38;5;241m=\u001b[39m q[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdocument\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m----> 8\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[43msearch_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m     relevance \u001b[38;5;241m=\u001b[39m [d[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m doc_id \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m results]\n\u001b[1;32m     10\u001b[0m     relevance_total\u001b[38;5;241m.\u001b[39mappend(relevance)\n",
      "Cell \u001b[0;32mIn[12], line 7\u001b[0m, in \u001b[0;36mVectorSearchEngine.search\u001b[0;34m(self, v_query, num_results)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msearch\u001b[39m(\u001b[38;5;28mself\u001b[39m, v_query, num_results\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m):\n\u001b[0;32m----> 7\u001b[0m     scores \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membeddings\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv_query\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m     idx \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margsort(\u001b[38;5;241m-\u001b[39mscores)[:num_results]\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdocuments[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m idx]\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for *: 'float' and 'dict'"
     ]
    }
   ],
   "source": [
    "# Evaluate the search function\n",
    "from tqdm.auto import tqdm\n",
    "def evaluate(ground_truth, search_function):\n",
    "    relevance_total = []\n",
    "\n",
    "    for q in tqdm(ground_truth):\n",
    "        doc_id = q['document']\n",
    "        results = search_function(q)\n",
    "        relevance = [d['id'] == doc_id for d in results]\n",
    "        relevance_total.append(relevance)\n",
    "\n",
    "    return {\n",
    "        'hit_rate': hit_rate(relevance_total)\n",
    "    }\n",
    "\n",
    "# Calculate the hit rate\n",
    "def hit_rate(relevance_total):\n",
    "    cnt = 0\n",
    "\n",
    "    for line in relevance_total:\n",
    "        if True in line:\n",
    "            cnt = cnt + 1\n",
    "\n",
    "    return cnt / len(relevance_total)\n",
    "\n",
    "evaluate(ground_truth, search_engine.search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aed5b39-e8ba-4595-b7d1-892d9750f2c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
